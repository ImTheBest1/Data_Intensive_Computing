{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Using direct authentication\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in doRppAPICall(\"search/tweets\", n, params = params, retryOnRateLimit = retryOnRateLimit, :\n",
      "“5000 tweets were requested but the API can only return 302”"
     ]
    }
   ],
   "source": [
    "# install.packages(\"twitterR\")\n",
    "# install.packages(\"ROAuth\")\n",
    "# install.packages(\"RCurl\")\n",
    "\n",
    "library(twitteR)\n",
    "library(ROAuth)\n",
    "library(RCurl)\n",
    "\n",
    "require(twitteR)\n",
    "require(RCurl)\n",
    "\n",
    "consumer_key <- \"iFX9JC9k1fo44ezw1ye0uD1QX\"\n",
    "consumer_secret <- \"lmIrg9KZXLLlX06kJKMqAoeRMEGUlOA9FoZo9u9AAqSzwvpLlM\"\n",
    "access_token <- \"807041899194421248-RBwaxwk0KW0oYseZ5yOuEzkobPHopT4\"\n",
    "access_secret <- \"rE5EzjRi4XLP6O5YQsLiLBrMDq5fQY7xL5He17urXXHC4\"\n",
    "\n",
    "fileName <-\"tweetsDF.csv\"\n",
    "#------------step1--------------------\n",
    "# create twitter connections\n",
    "setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)\n",
    "\n",
    "# -----------step2--------------------\n",
    "# search tweets\n",
    "# 1) 你可以直接使用以下这些词: sick, influenza, flu, ill, H1N1....\n",
    "# 2) 可以使用以下一些词，但是搜索完毕，在有效的地址显示的data，读一下text的大概内容，确定内容和flu有关:\n",
    "#     dose, nasal passages, bronchi\n",
    "cur_tweets <- searchTwitter(\"nasal passages\", n=5000)\n",
    "\n",
    "#------------step3-----------------\n",
    "# convert twitteR lists to data frame\n",
    "cur_tweetsDF <- twListToDF(cur_tweets)\n",
    "# store the tweets Data frame has location\n",
    "cur_tweetsDF <- cur_tweetsDF[!(is.na(cur_tweetsDF$longitude)) | !(is.na(cur_tweetsDF$latitude)),]\n",
    "# store the tweets has text, location, and id\n",
    "cur_tweetsDF <- cur_tweetsDF[c(\"text\", \"id\",\"longitude\", \"latitude\")]\n",
    "\n",
    "#------------step4: combine previous with previous csv.file----------------------\n",
    "# read previous tweets data frame csv file\n",
    "pre_tweetsDF <- read.csv(fileName, header=T, sep=\",\")\n",
    "pre_tweetsDF <- pre_tweetsDF[c(\"text\", \"id\",\"longitude\", \"latitude\")]\n",
    "\n",
    "# combine two csv files\n",
    "finalDF <- rbind(cur_tweetsDF, pre_tweetsDF)\n",
    "# remove the data if they are all the same\n",
    "dropX <-\"X\"\n",
    "finalDF <-finalDF[ , !(names(finalDF) %in% dropX)]\n",
    "finalDF <-finalDF[!duplicated(finalDF), ]\n",
    "\n",
    "# ----------step5: store final data in the csv file\n",
    "write.csv(finalDF,fileName)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
